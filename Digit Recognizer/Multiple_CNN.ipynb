{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Recognizer\n",
    "\n",
    "Digit Recognition using Multiple CNNs and then summing up the probablities of all CNNs to predict an accurate answer.\n",
    "Also, generating additional 25 million images to achceive data augmentation, using resizing, rotation, zoom, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# LOAD LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import layers\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cd31c62c12088bfa6f2b26dcecc714182627c767"
   },
   "source": [
    "# Load Kaggle's 42,000 training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d71b3fa2b10620dc8870352fc18d4548f824a88a"
   },
   "outputs": [],
   "source": [
    "# LOAD THE DATA\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b3c56055d1ba56d28d982f9647c33439c46753ff"
   },
   "outputs": [],
   "source": [
    "# PREPARE DATA FOR NEURAL NETWORK\n",
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop('label',axis = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = test.values.reshape(-1,28,28,1)\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cfcb89d7d2dab632986e80d9f68d194c3c1c9e9f"
   },
   "source": [
    "# Generate 25 million more images!! (Data Augmentation)\n",
    "by randomly rotating, scaling, and shifting Kaggle's 42,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "1e61e07d14b9b012748fdaac9eaf02e5263a475e"
   },
   "outputs": [],
   "source": [
    "# CREATE MORE IMAGES VIA DATA AUGMENTATION\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             rotation_range=10,\n",
    "                             zoom_range = 0.10,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ea116cd3688cb26ac79b9fecc7309a1aebf3b63"
   },
   "source": [
    "# Build n-number of Convolutional Neural Networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f6703f3f53c659e95579122755454899d842722a"
   },
   "outputs": [],
   "source": [
    "# BUILD CONVOLUTIONAL NEURAL NETWORKS\n",
    "\n",
    "def initiate_model(nets=1):\n",
    "    model = [0] *nets\n",
    "    for j in range(nets):\n",
    "        model[j] = Sequential()\n",
    "\n",
    "        model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
    "        model[j].add(BatchNormalization())\n",
    "        model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "        model[j].add(BatchNormalization())\n",
    "        model[j].add(Dropout(0.4))\n",
    "        model[j].add(MaxPooling2D((2,2)))\n",
    "\n",
    "        model[j].add(Conv2D(128, kernel_size = 3, activation='relu'))\n",
    "        model[j].add(BatchNormalization())\n",
    "        model[j].add(Dropout(0.4))\n",
    "        model[j].add(MaxPooling2D((2,2)))\n",
    "\n",
    "        model[j].add(Flatten())\n",
    "        model[j].add(Dropout(0.4))\n",
    "        model[j].add(Dense(10, activation='softmax'))\n",
    "\n",
    "        # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
    "        model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 131,466\n",
      "Trainable params: 131,018\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initiate_model(1)[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e433661c7762b947c0fbfc4ad3f5e1d2e056312c"
   },
   "source": [
    "# Training CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "9f1dd8a54aa0fab8530c0095f7d4c4b35984ea6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 153s - loss: 0.6487 - accuracy: 0.8221 - val_loss: 0.1376 - val_accuracy: 0.9614\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "# DECREASE LEARNING RATE EACH EPOCH\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "# TRAIN NETWORKS\n",
    "epochs = 1\n",
    "nets=1\n",
    "model_list = initiate_model(nets)\n",
    "history_list = [0] * nets\n",
    "\n",
    "for j in range(nets):\n",
    "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.1)\n",
    "    X_val2 = X_val2/255\n",
    "    history_list[j] = model_list[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n",
    "                                                  validation_data = (X_val2,Y_val2),\n",
    "                                                  epochs = epochs, steps_per_epoch = X_train2.shape[0]//64, callbacks=[annealer], verbose=2)\n",
    "    #print(\"CNN {0:d}:, Train accuracy={1:.5f}, Validation accuracy={2:.5f}\".format(j+1, max(history_list[j].history['acc']), max(history_list[j].history['val_acc'])))\n",
    "print('Training Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28b78b6502d2d1c993555725383f3e30728fa5be"
   },
   "source": [
    "# Ensemble 15 CNN predictions and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "6e4e01ffe692c34c555bdbf5d606611f9a128b9c"
   },
   "outputs": [],
   "source": [
    "# ENSEMBLE PREDICTIONS AND SUBMIT\n",
    "results = np.zeros( (X_test.shape[0],10) ) \n",
    "for j in range(nets):\n",
    "    results = results + model_list[j].predict(X_test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"Multiple_CNN.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d55f8c054432beabeed62024a998234c7cdb7b6"
   },
   "source": [
    "# Credits\n",
    "The code here was inspired by the following outstanding Kaggle kernels (in addition to the publications above).\n",
    "\n",
    "* [Yassine Ghouzam][1] - [Introduction to CNN Keras - 0.997 (top 6%)][2]\n",
    "* [Peter Grenholm][5] - [Welcome to deep learning (CNN 99%)][6]\n",
    "* [Ding Li][3] - [Digits Recognition With CNN Keras][4]\n",
    "* [Aditya Soni][7] - [MNIST with Keras for Beginners(.99457)][8]\n",
    "\n",
    "[1]:https://www.kaggle.com/yassineghouzam\n",
    "[2]:https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\n",
    "[3]:https://www.kaggle.com/dingli\n",
    "[4]:https://www.kaggle.com/dingli/digits-recognition-with-cnn-keras\n",
    "[5]:https://www.kaggle.com/toregil\n",
    "[6]:https://www.kaggle.com/toregil/welcome-to-deep-learning-cnn-99/\n",
    "[8]:https://www.kaggle.com/adityaecdrid/mnist-with-keras-for-beginners-99457/\n",
    "[7]:https://www.kaggle.com/adityaecdrid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
