{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adagrad_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9HSdD5pyP8sq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myXil-jvorqT",
        "colab_type": "text"
      },
      "source": [
        "# Adagrad Project: CiFAR10 Image Classification\n",
        "This notebook demonstrates image classification on the, \n",
        " \n",
        "\n",
        "*   CiFar10 dataset, imported from the `tensorflow.keras.datasets` API,\n",
        "*   using Visual Geometry Group (VGG)-16 Deep Neural Network,\n",
        "*   with initial weights set to pre-trained parameters on the ImageNet Dataset.\n",
        "\n",
        "The model features a custom classifier designed to classify the 10 classes in the CiFAR10 dataset. </br> All layers are further trained to achieve maximum `val_accuracy`\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "<!--import tensorflow as tf\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbPF6LhSpB7N",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-3W2UzKlROg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#import tensorflow_datasets as tfds\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "#tfds.disable_progress_bar()\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgJjcKsyqf7b",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "  ## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc31Hka0cIFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_keras_data():\n",
        "  (x_train,y_train),(x_test,y_test) = keras.datasets.cifar10.load_data()\n",
        "  \n",
        "  #Normalise X values to between -1 to 1\n",
        "  return x_train/127 - 1, y_train, x_test/127 - 1 ,y_test\n",
        "\n",
        "\n",
        "def create_model():\n",
        "  base_model = tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "  base_model.trainable = True\n",
        "\n",
        "  #Make Sequential class instance to add classifier layers\n",
        "  model = Sequential(base_model)\n",
        "  model.add(layers.GlobalAveragePooling2D())\n",
        "  model.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HSdD5pyP8sq",
        "colab_type": "text"
      },
      "source": [
        "## Display sample image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9gZeqdEKDHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate training and test dataset\n",
        "x_train, y_train, x_test, y_test = get_keras_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-rqHUjEO9Kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "d46e8201-5ee8-4084-992a-e6d51089cb90"
      },
      "source": [
        "img = x_train[0].reshape((32,32,3))\n",
        "plt.imshow(img,aspect=\"auto\")\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jei-EYlPaDd0",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "....base Model Visual Geometry Group (VGG16)\n",
        "<!-- #callbacks = [tf.keras.callbacks.EarlyStopping(monitor='accuracy', baseline=0.98, min_delta=0.001, patience=1, mode='auto')] -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w86XZF9J5hz8",
        "colab_type": "text"
      },
      "source": [
        "### Distribution Strategy on GPUs\n",
        "...using `tensorflow.distribute.MirroredStrategy` for faster training\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PieeiLUJlXB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "68c7fcba-07c3-4d65-c63a-079c24cc4c61"
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "with mirrored_strategy.scope():\n",
        "  model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 14,719,818\n",
            "Trainable params: 14,719,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kw8mj9D8Dpn",
        "colab_type": "text"
      },
      "source": [
        "Listing out number of available GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLm_LmU01ZnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " len(tf.config.experimental.list_physical_devices('GPU'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7fKZGaP8LsO",
        "colab_type": "text"
      },
      "source": [
        "### Compile Model\n",
        "Optimizer: `ADAM`</br>\n",
        "Loss: `sparse_categorical_crossentropy`</br>\n",
        "Metric: `accuracy`</br>\n",
        "Learning Rate: `0.0001`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZLK8v_8labu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(Adam(0.0001),loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMgSB4KtDNYl",
        "colab_type": "text"
      },
      "source": [
        "...training for 12 epochs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZseR-VCloRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "0a13be5d-c5cd-4b7b-c714-dce60d112b85"
      },
      "source": [
        "history = model.fit(x_train,y_train,batch_size=64,epochs=12,validation_split=0.2) # VGG16 lr=0.0001 imagenet weights"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "625/625 [==============================] - ETA: 0s - accuracy: 0.7128 - loss: 0.8267INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "625/625 [==============================] - 53s 85ms/step - accuracy: 0.7128 - loss: 0.8267 - val_accuracy: 0.8038 - val_loss: 0.5675\n",
            "Epoch 2/12\n",
            "625/625 [==============================] - 52s 83ms/step - accuracy: 0.8331 - loss: 0.4837 - val_accuracy: 0.8298 - val_loss: 0.4944\n",
            "Epoch 3/12\n",
            "625/625 [==============================] - 53s 84ms/step - accuracy: 0.8824 - loss: 0.3387 - val_accuracy: 0.8453 - val_loss: 0.4529\n",
            "Epoch 4/12\n",
            "625/625 [==============================] - 53s 85ms/step - accuracy: 0.9182 - loss: 0.2360 - val_accuracy: 0.8402 - val_loss: 0.5115\n",
            "Epoch 5/12\n",
            "625/625 [==============================] - 53s 85ms/step - accuracy: 0.9455 - loss: 0.1595 - val_accuracy: 0.8476 - val_loss: 0.4827\n",
            "Epoch 6/12\n",
            "625/625 [==============================] - 54s 86ms/step - accuracy: 0.9583 - loss: 0.1199 - val_accuracy: 0.8438 - val_loss: 0.5326\n",
            "Epoch 7/12\n",
            "625/625 [==============================] - 53s 84ms/step - accuracy: 0.9706 - loss: 0.0837 - val_accuracy: 0.8405 - val_loss: 0.6095\n",
            "Epoch 8/12\n",
            "625/625 [==============================] - 52s 83ms/step - accuracy: 0.9743 - loss: 0.0733 - val_accuracy: 0.8536 - val_loss: 0.6056\n",
            "Epoch 9/12\n",
            "625/625 [==============================] - 52s 83ms/step - accuracy: 0.9795 - loss: 0.0617 - val_accuracy: 0.8580 - val_loss: 0.5674\n",
            "Epoch 10/12\n",
            "625/625 [==============================] - 52s 83ms/step - accuracy: 0.9819 - loss: 0.0532 - val_accuracy: 0.8544 - val_loss: 0.6541\n",
            "Epoch 11/12\n",
            "625/625 [==============================] - 52s 83ms/step - accuracy: 0.9816 - loss: 0.0553 - val_accuracy: 0.8542 - val_loss: 0.6136\n",
            "Epoch 12/12\n",
            "625/625 [==============================] - 52s 83ms/step - accuracy: 0.9850 - loss: 0.0456 - val_accuracy: 0.8547 - val_loss: 0.5967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKNTiZfmYm4h",
        "colab_type": "text"
      },
      "source": [
        "## Inferences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2gsDs2xMyIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0a1f6897-adbe-4bb5-c9ed-5b0e502a96e3"
      },
      "source": [
        "import time\n",
        "toc = time.time()\n",
        "results = model.evaluate(x_test,y_test,batch_size=64, return_dict=True)\n",
        "tic = time.time()\n",
        "print(results)\n",
        "print('Latency: {} milli-seconds'.format((tic-toc)*1000))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 4s 28ms/step - accuracy: 0.8505 - loss: 0.6111\n",
            "{'accuracy': 0.8504999876022339, 'loss': 0.611142098903656}\n",
            "Latency: 4817.401170730591 milli-seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdLpLxQKAh3R",
        "colab_type": "text"
      },
      "source": [
        "### Saving Test data\n",
        "...as `.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mrn_Lxl_zMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_all = x_test.reshape(x_test.shape[0],32*32,3)\n",
        "pd.DataFrame(x_test_all[:][:][0]).to_csv('x_test_channelR.csv')\n",
        "pd.DataFrame(x_test_all[:][:][1]).to_csv('x_test_channelG.csv')\n",
        "pd.DataFrame(x_test_all[:][:][2]).to_csv('x_test_channelB.csv')\n",
        "pd.DataFrame(y_test).to_csv('y_test.csv')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DeoC8DKCNdV",
        "colab_type": "text"
      },
      "source": [
        "...and as `.npy`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OCbCCrJBhg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('x-test', x_test)\n",
        "np.save('y-test', y_test)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAZOzUk6Jd65",
        "colab_type": "text"
      },
      "source": [
        "## Saving the model to disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1NforNb3U88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "bedd2de0-0a6b-4610-9d31-cfdddfc7f7c6"
      },
      "source": [
        "model.save('vgg16_imagenet_0001')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: vgg16_imagenet_0001/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udLlJH6vDrod",
        "colab_type": "text"
      },
      "source": [
        "### Create Zip of model to download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KtqZ5WB9iM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r -q VGG16 vgg16_imagenet_0001/"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}